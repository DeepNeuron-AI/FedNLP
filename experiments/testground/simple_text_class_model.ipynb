{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from typing import Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard pytorch, black-box to flower\n",
    "Simple text model according to: https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, offsets, label_list = [], [0], []\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = list(AG_NEWS(split='train'))\n",
    "valid_iter = list(AG_NEWS(split='test'))\n",
    "train_dataloaders = [\n",
    "    DataLoader(train_iter[i:i+len(train_iter)//10], batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "    for i in range(0, len(train_iter), len(train_iter)//10)\n",
    "]\n",
    "valid_dataloaders = [\n",
    "    DataLoader(valid_iter[i:i+len(valid_iter)//10], batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "    for i in range(0, len(valid_iter), len(valid_iter)//10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TextClassificationModel(vocab_size=100, embed_dim=1000, num_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader: DataLoader, model: nn.Module, epochs: int):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=1.0)\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            if idx % log_interval == 0 and idx > 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                # print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                #     '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                #                                 total_acc/total_count))\n",
    "                total_acc, total_count = 0, 0\n",
    "                start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader: DataLoader, model: nn.Module):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test centralised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = train_dataloaders[0]\n",
    "# valloader = valid_dataloaders[0]\n",
    "\n",
    "# vocab_size = len(vocab)\n",
    "# emsize = 64\n",
    "# num_class = len(set([label for (label, text) in train_iter]))\n",
    "# net = TextClassificationModel(vocab_size=vocab_size, embed_dim=emsize, num_class=num_class).to(device)\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     train(trainloader, net, epochs=1)\n",
    "#     accuracy = evaluate(valloader, net)\n",
    "#     print(f\"Epoch {epoch+1}: validation accuracy {accuracy}\")\n",
    "\n",
    "# accuracy = evaluate(valloader, net)\n",
    "# print(f\"Final test set performance:\\n\\taccuracy {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning wrapper\n",
    "Where we modify the training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class FlowerClient(flwr.client.NumPyClient):\n",
    "    def __init__(self, net: nn.Module, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "        train(self.trainloader, self.net,  epochs=1)\n",
    "        return self.get_parameters(), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.net.load_state_dict(state_dict, strict=True)\n",
    "        accuracy = evaluate(self.valloader, self.net)\n",
    "        return float(0.5), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    # define stuff\n",
    "    vocab_size = len(vocab)\n",
    "    emsize = 64\n",
    "    num_class = len(set([label for (label, text) in train_iter]))\n",
    "\n",
    "    # Load model\n",
    "    net = TextClassificationModel(\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=emsize,\n",
    "        num_class=num_class\n",
    "    ).to(device)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = train_dataloaders[int(cid)]\n",
    "    valloader = valid_dataloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-04-18 12:31:23,246 | app.py:147 | Ray initialized with resources: {'object_store_memory': 4390517145.0, 'memory': 8781034292.0, 'node:172.24.46.98': 1.0, 'CPU': 16.0}\n",
      "INFO:flower:Ray initialized with resources: {'object_store_memory': 4390517145.0, 'memory': 8781034292.0, 'node:172.24.46.98': 1.0, 'CPU': 16.0}\n",
      "INFO flower 2022-04-18 12:31:23,248 | app.py:156 | Starting Flower simulation running: {'num_rounds': 5}\n",
      "INFO:flower:Starting Flower simulation running: {'num_rounds': 5}\n",
      "INFO flower 2022-04-18 12:31:23,250 | server.py:84 | Initializing global parameters\n",
      "INFO:flower:Initializing global parameters\n",
      "INFO flower 2022-04-18 12:31:23,251 | server.py:249 | Requesting initial parameters from one random client\n",
      "INFO:flower:Requesting initial parameters from one random client\n",
      "INFO flower 2022-04-18 12:31:24,443 | server.py:252 | Received initial parameters from one random client\n",
      "INFO:flower:Received initial parameters from one random client\n",
      "INFO flower 2022-04-18 12:31:24,445 | server.py:86 | Evaluating initial parameters\n",
      "INFO:flower:Evaluating initial parameters\n",
      "INFO flower 2022-04-18 12:31:24,446 | server.py:99 | FL starting\n",
      "INFO:flower:FL starting\n",
      "DEBUG flower 2022-04-18 12:31:24,447 | server.py:202 | fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG:flower:fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:35:24,213 | server.py:214 | fit_round received 10 results and 0 failures\n",
      "DEBUG:flower:fit_round received 10 results and 0 failures\n",
      "WARNING flower 2022-04-18 12:35:24,913 | fedavg.py:237 | No fit_metrics_aggregation_fn provided\n",
      "WARNING:flower:No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-04-18 12:35:24,916 | server.py:159 | evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG:flower:evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:35:26,826 | server.py:171 | evaluate_round received 5 results and 0 failures\n",
      "DEBUG:flower:evaluate_round received 5 results and 0 failures\n",
      "WARNING flower 2022-04-18 12:35:26,827 | fedavg.py:268 | No evaluate_metrics_aggregation_fn provided\n",
      "WARNING:flower:No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-04-18 12:35:26,828 | server.py:202 | fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG:flower:fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:39:29,816 | server.py:214 | fit_round received 10 results and 0 failures\n",
      "DEBUG:flower:fit_round received 10 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:39:30,084 | server.py:159 | evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG:flower:evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:39:32,350 | server.py:171 | evaluate_round received 5 results and 0 failures\n",
      "DEBUG:flower:evaluate_round received 5 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:39:32,352 | server.py:202 | fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG:flower:fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:43:36,248 | server.py:214 | fit_round received 10 results and 0 failures\n",
      "DEBUG:flower:fit_round received 10 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:43:36,593 | server.py:159 | evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG:flower:evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:43:38,005 | server.py:171 | evaluate_round received 5 results and 0 failures\n",
      "DEBUG:flower:evaluate_round received 5 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:43:38,007 | server.py:202 | fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG:flower:fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:47:29,829 | server.py:214 | fit_round received 10 results and 0 failures\n",
      "DEBUG:flower:fit_round received 10 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:47:30,022 | server.py:159 | evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG:flower:evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:47:31,129 | server.py:171 | evaluate_round received 5 results and 0 failures\n",
      "DEBUG:flower:evaluate_round received 5 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:47:31,131 | server.py:202 | fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG:flower:fit_round: strategy sampled 10 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:51:16,949 | server.py:214 | fit_round received 10 results and 0 failures\n",
      "DEBUG:flower:fit_round received 10 results and 0 failures\n",
      "DEBUG flower 2022-04-18 12:51:18,204 | server.py:159 | evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG:flower:evaluate_round: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flower 2022-04-18 12:51:27,128 | server.py:171 | evaluate_round received 5 results and 0 failures\n",
      "DEBUG:flower:evaluate_round received 5 results and 0 failures\n",
      "INFO flower 2022-04-18 12:51:27,130 | server.py:138 | FL finished in 1202.682829267\n",
      "INFO:flower:FL finished in 1202.682829267\n",
      "INFO flower 2022-04-18 12:51:27,141 | app.py:149 | app_fit: losses_distributed [(1, 0.5), (2, 0.5), (3, 0.5), (4, 0.5), (5, 0.5)]\n",
      "INFO:flower:app_fit: losses_distributed [(1, 0.5), (2, 0.5), (3, 0.5), (4, 0.5), (5, 0.5)]\n",
      "INFO flower 2022-04-18 12:51:27,142 | app.py:150 | app_fit: metrics_distributed {}\n",
      "INFO:flower:app_fit: metrics_distributed {}\n",
      "INFO flower 2022-04-18 12:51:27,143 | app.py:151 | app_fit: losses_centralized []\n",
      "INFO:flower:app_fit: losses_centralized []\n",
      "INFO flower 2022-04-18 12:51:27,144 | app.py:152 | app_fit: metrics_centralized {}\n",
      "INFO:flower:app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.5\n",
       "\tround 2: 0.5\n",
       "\tround 3: 0.5\n",
       "\tround 4: 0.5\n",
       "\tround 5: 0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = flwr.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "        fraction_eval=0.5,  # Sample 50% of available clients for evaluation\n",
    "        min_fit_clients=10,  # Never sample less than 10 clients for training\n",
    "        min_eval_clients=5,  # Never sample less than 5 clients for evaluation\n",
    "        min_available_clients=10,  # Wait until all 10 clients are available\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "flwr.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=10,\n",
    "    num_rounds=5,\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15b74998ddbe8dd31bebbc741a726c3e9aabbd66904b3d54eee12716ed76545d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
